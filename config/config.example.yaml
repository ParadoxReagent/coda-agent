# ── Required ──────────────────────────────────────
llm:
  default_provider: "anthropic"
  default_model: "claude-sonnet-4-5-20250514"
  providers:
    anthropic:
      type: "anthropic"
      api_key: ""  # or set ANTHROPIC_API_KEY env var
      models:
        - "claude-sonnet-4-5-20250514"
        - "claude-haiku-3-5-20241022"

discord:
  bot_token: ""       # or DISCORD_BOT_TOKEN
  channel_id: ""      # or DISCORD_CHANNEL_ID
  allowed_user_ids: [] # or DISCORD_ALLOWED_USER_IDS (comma-separated)

# ── Defaults (override if needed) ─────────────────
redis:
  url: "redis://localhost:6379"

database:
  url: "postgresql://localhost:5432/coda"

server:
  port: 3000
  host: "127.0.0.1"

skills:
  external_dirs: []
  agent_skill_dirs: []

# ── Enabled by default (zero-config) ─────────────
weather: {}         # Free NWS API, no key needed
# doctor runs automatically — see integrations_readme.md for tuning

# ── Optional Integrations ────────────────────────
# Each section below is OFF unless configured.
# See integrations_readme.md and skills_readme.md for full docs.
#
# Env var quick reference (auto-scaffolds providers when set):
#   ANTHROPIC_API_KEY, GOOGLE_API_KEY, OPENAI_API_KEY, OPENROUTER_API_KEY
#   FIRECRAWL_API_KEY        → web scraping/search
#   MEMORY_API_KEY           → semantic memory
#   EXECUTION_ENABLED=true   → Docker code execution
#   SLACK_APP_TOKEN + SLACK_BOT_TOKEN → Slack interface
#
# Tier routing (cost optimization):
#   TIER_ENABLED=true
#   TIER_LIGHT_MODEL=claude-haiku-3-5-20241022
#   TIER_HEAVY_MODEL=claude-sonnet-4-5-20250514
#
# Uncomment sections below to customize defaults:

# google:
#   type: "google"
#   api_key: ""  # or GOOGLE_API_KEY
#   models:
#     - "gemini-2.0-flash"

# openai:
#   type: "openai_compat"
#   base_url: "https://api.openai.com/v1"
#   api_key: ""  # or OPENAI_API_KEY
#   models:
#     - "gpt-4o"

# firecrawl:
#   api_key: ""  # or FIRECRAWL_API_KEY (required for cloud)
#   # api_url: "http://localhost:3002"  # for self-hosted instance

# memory:
#   api_key: ""  # or MEMORY_API_KEY
#   base_url: "http://memory-service:8010"

# execution:
#   enabled: false  # or EXECUTION_ENABLED=true
#   default_image: "python:3.12-slim"
#   timeout: 60
#   max_memory: "512m"
#   network_enabled: false
#   allowed_images:  # Glob patterns for allowed Docker images
#     - "python:*"
#     - "node:*"
#     - "ubuntu:*"
#     - "alpine:*"
#     - "coda-skill-*"  # Pre-built skill images (use npm run build:skill-images)

# slack:
#   app_token: ""  # or SLACK_APP_TOKEN
#   bot_token: ""  # or SLACK_BOT_TOKEN
#   channel_id: ""
#   allowed_user_ids: []

# subagents:
#   enabled: true
#   default_timeout_minutes: 5
#   max_concurrent_per_user: 3

# doctor:
#   enabled: true
#   pattern_window_seconds: 300
#   pattern_threshold: 10
#   output_repair:
#     enabled: true
#     quick_fix_only: true  # SECURITY: true = no LLM repair (prevents injection)

# alerts:
#   quiet_hours:
#     enabled: false
#     start: "22:00"
#     end: "07:00"
