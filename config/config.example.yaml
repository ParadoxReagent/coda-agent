# ── Required ──────────────────────────────────────
llm:
  default_provider: "anthropic"
  default_model: "claude-sonnet-4-5-20250514"
  providers:
    anthropic:
      type: "anthropic"
      api_key: ""  # or set ANTHROPIC_API_KEY env var
      models:
        - "claude-sonnet-4-5-20250514"
        - "claude-haiku-3-5-20241022"

discord:
  bot_token: ""       # or DISCORD_BOT_TOKEN
  channel_id: ""      # or DISCORD_CHANNEL_ID
  allowed_user_ids: [] # or DISCORD_ALLOWED_USER_IDS (comma-separated)

# ── Defaults (override if needed) ─────────────────
redis:
  url: "redis://localhost:6379"

database:
  url: "postgresql://localhost:5432/coda"

server:
  port: 3000
  host: "127.0.0.1"

skills:
  external_dirs: []
  agent_skill_dirs: []

# ── Enabled by default (zero-config) ─────────────
weather: {}         # Free NWS API, no key needed
# doctor runs automatically — see integrations_readme.md for tuning

# ── Optional Integrations ────────────────────────
# Each section below is OFF unless configured.
# See integrations_readme.md and skills_readme.md for full docs.
#
# Env var quick reference (auto-scaffolds providers when set):
#   ANTHROPIC_API_KEY, GOOGLE_API_KEY, OPENAI_API_KEY, OPENROUTER_API_KEY
#   FIRECRAWL_API_KEY        → web scraping/search
#   MEMORY_API_KEY           → semantic memory
#   EXECUTION_ENABLED=true   → Docker code execution
#   SLACK_APP_TOKEN + SLACK_BOT_TOKEN → Slack interface
#
# Tier routing (cost optimization):
#   TIER_ENABLED=true
#   TIER_LIGHT_MODEL=claude-haiku-3-5-20241022
#   TIER_HEAVY_MODEL=claude-sonnet-4-5-20250514
#
# Uncomment sections below to customize defaults:

# google:
#   type: "google"
#   api_key: ""  # or GOOGLE_API_KEY
#   models:
#     - "gemini-2.0-flash"

# openai:
#   type: "openai_compat"
#   base_url: "https://api.openai.com/v1"
#   api_key: ""  # or OPENAI_API_KEY
#   models:
#     - "gpt-4o"

# firecrawl:
#   api_key: ""  # or FIRECRAWL_API_KEY (required for cloud)
#   # api_url: "http://localhost:3002"  # for self-hosted instance

# memory:
#   api_key: ""  # or MEMORY_API_KEY
#   base_url: "http://memory-service:8010"

# execution:
#   enabled: false  # or EXECUTION_ENABLED=true
#   default_image: "python:3.12-slim"
#   timeout: 60
#   max_memory: "512m"
#   network_enabled: false
#   allowed_images:  # Glob patterns for allowed Docker images
#     - "python:*"
#     - "node:*"
#     - "ubuntu:*"
#     - "alpine:*"
#     - "coda-skill-*"  # Pre-built skill images (use npm run build:skill-images)

# slack:
#   app_token: ""  # or SLACK_APP_TOKEN
#   bot_token: ""  # or SLACK_BOT_TOKEN
#   channel_id: ""
#   allowed_user_ids: []

# subagents:
#   enabled: true
#   default_timeout_minutes: 5
#   max_concurrent_per_user: 3

# doctor:
#   enabled: true
#   pattern_window_seconds: 300
#   pattern_threshold: 10
#   output_repair:
#     enabled: true
#     quick_fix_only: true  # SECURITY: true = no LLM repair (prevents injection)

# alerts:
#   quiet_hours:
#     enabled: false
#     start: "22:00"
#     end: "07:00"

# MCP (Model Context Protocol) Integration
# Connect to external MCP servers and use their tools as coda skills
# See docs/mcp-integration.md for complete documentation
#
# mcp:
#   servers:
#     # Example 1: PDF processing (Python MCP server)
#     # Built-in server for PDF operations (merge, split, extract, rotate)
#     pdf:
#       enabled: true
#       transport:
#         type: stdio
#         command: python3
#         args: ["src/integrations/mcp/servers/pdf/server.py"]
#       description: "PDF processing tools (merge, split, extract text/tables, rotate)"
#       tool_timeout_ms: 120000  # 2 minutes for large PDFs
#       max_response_size: 500000  # 500KB for extracted text/tables
#
#     # Example 2: Local filesystem access via stdio
#     # Runs an MCP server as a child process
#     filesystem:
#       enabled: true
#       transport:
#         type: stdio
#         command: npx
#         args: ["-y", "@modelcontextprotocol/server-filesystem", "/allowed/directory"]
#         env:  # Optional environment variables
#           DEBUG: "mcp:*"
#         cwd: /working/directory  # Optional working directory
#       tool_blocklist: ["write_file", "delete_file"]  # Block dangerous operations
#       description: "Read-only filesystem access"
#       timeout_ms: 30000        # Connection timeout
#       tool_timeout_ms: 60000   # Per-tool execution timeout
#       max_response_size: 100000  # Max response size in bytes (100KB)
#
#     # Example 3: Remote MCP service via HTTP
#     # For production deployments, microservices, or external APIs
#     github:
#       enabled: false
#       transport:
#         type: http
#         url: https://mcp-github.example.com  # Remote URL
#         # Or use environment variables (recommended for secrets):
#         # url: ${MCP_GITHUB_URL}
#         headers:
#           Authorization: "Bearer ${GITHUB_TOKEN}"  # From env: GITHUB_TOKEN
#           X-Custom-Header: "value"
#       requires_confirmation: ["create_issue", "create_pull_request"]
#       sensitive_tools: ["get_token"]  # Logged at info level
#       timeout_ms: 60000
#
#     # Example 4: Docker container (same network)
#     # When both coda-agent and MCP server are in Docker
#     docker_service:
#       enabled: false
#       transport:
#         type: http
#         url: http://mcp-filesystem-container:8080  # Container name
#         # Or Docker Compose service name:
#         # url: http://mcp-service:8080
#       description: "Containerized MCP filesystem"
#
#     # Example 5: Host machine (when coda-agent is in Docker)
#     host_service:
#       enabled: false
#       transport:
#         type: http
#         # Mac/Windows:
#         url: http://host.docker.internal:8080
#         # Linux (requires --add-host=host-gateway:host-gateway):
#         # url: http://host-gateway:8080
#
#     # Example 6: Tool allowlist (strict mode)
#     # Only specified tools are available
#     database:
#       enabled: false
#       transport:
#         type: http
#         url: ${MCP_DATABASE_URL}
#       tool_allowlist:  # Allowlist takes precedence over blocklist
#         - query_read_only
#         - list_tables
#         - get_schema
#       # tool_blocklist is ignored when tool_allowlist is set
#       requires_confirmation: ["execute_migration"]
#       sensitive_tools: ["query_read_only"]
#
# Environment Variable Substitution:
# All string values support ${VAR_NAME} syntax for secrets.
#
# Method 1: .env file (recommended for local development)
#   Add to .env in project root:
#     MCP_GITHUB_URL=https://mcp-github.example.com
#     GITHUB_TOKEN=ghp_xxxxxxxxxxxx
#     MCP_DATABASE_URL=http://mcp-db:8080
#
# Method 2: Export directly (useful for Docker/CI)
#   export GITHUB_TOKEN="ghp_xxxxxxxxxxxx"
#   export MCP_GITHUB_URL="https://mcp-github.example.com"
#
# Security Notes:
# - Always use HTTPS for remote URLs (except localhost/internal networks)
# - Use environment variables for secrets (never commit tokens)
# - Set tool_blocklist to prevent dangerous operations
# - Mark sensitive tools with sensitive_tools
# - Use requires_confirmation for destructive actions
# - Set appropriate max_response_size to prevent memory issues
